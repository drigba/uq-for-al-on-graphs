{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_names = [\"aleatoric_propagated\", \"educated_random\", \"augment_latent\", \"age\",\"anrmab\", \"entropy\",\"tta_expected_query_score\"]\n",
    "metrics_dict_cora_gcn = load_results(\"cora_ml\", \"gcn\", strategies_names, save=False, cached=True, cache_path=\"../other_data\")\n",
    "all_metrics[(\"cora_ml\", \"gcn\")] = metrics_dict_cora_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_names = [\"aleatoric_propagated\", \"age\",\"anrmab\", \"entropy\"]\n",
    "metrics_dict_cora_sgc = load_results(\"cora_ml\", \"sgc\", strategies_names, save=False, cached=False, cache_path=\"../other_data\")\n",
    "all_metrics[(\"cora_ml\", \"sgc\")] = metrics_dict_cora_sgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"citeseer\", \"pubmed\", \"amazon_photos\"]:\n",
    "    for model in [\"gcn\", \"sgc\"]:\n",
    "        strategies_names = [\"aleatoric_propagated\", \"age\",\"anrmab\", \"entropy\"]\n",
    "        metrics_dict = load_results(dataset, model, strategies_names, save=False, cached=False, cache_path=\"../other_data\")\n",
    "        all_metrics[(dataset, model)] = metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = combine_geem_metrics(\"cora_ml\",\"fmask_emask_200_filter_probs_0.5_0.4\")\n",
    "agg, stds = aggregate_geem_metrics(\"cora_ml\")\n",
    "# all_metrics[(\"cora_ml\", \"gcn\")][\"geem\"] = (agg[\"accuracy/test\"], stds[\"accuracy/test\"], agg, runs)\n",
    "all_metrics[(\"cora_ml\", \"sgc\")][\"geem\"] = (agg[\"accuracy/test\"], stds[\"accuracy/test\"], agg, runs)\n",
    "metrics_dict_cora_gcn[\"geem\"] = (agg[\"accuracy/test\"], stds[\"accuracy/test\"], agg, runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg, stds = aggregate_geem_metrics(\"pubmed\")\n",
    "agg[\"accuracy/test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combineds = {}\n",
    "for (dataset,model), metrics_dict in all_metrics.items():\n",
    "    df_combined, df = create_df(metrics_dict)\n",
    "    df_combineds[(dataset,model)] = (df_combined,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cora_sgc  = df_combineds[('pubmed', 'gcn')][0]\n",
    "# df_cora_sgc_t  = df_combineds[('cora_ml', 'sgc')][1]\n",
    "df_cora_sgc[\"strategy\"] = [i[0] for i in df_cora_sgc.index.str.split(\"_\")]\n",
    "df_cora_sgc[\"tta\"] = [False if i[-1] == \"None\" else True for i in df_cora_sgc.index.str.split(\"_\")]\n",
    "\n",
    "df_cora_sgc_tta = df_cora_sgc[df_cora_sgc[\"tta\"]][[\"strategy\",\"28_mean\", \"28_std\", \"nalc\"]]\n",
    "df_cora_sgc_no_tta = df_cora_sgc[~df_cora_sgc[\"tta\"]][[\"strategy\",\"28_mean\", \"28_std\", \"nalc\"]]\n",
    "\n",
    "df_cora_sgc_merged = df_cora_sgc_tta.merge(df_cora_sgc_no_tta, on=\"strategy\", suffixes=(\"_tta\", \"_no_tta\"))\n",
    "df_cora_sgc_merged[\"diff\"] = df_cora_sgc_merged[\"28_mean_tta\"] - df_cora_sgc_merged[\"28_mean_no_tta\"]\n",
    "\n",
    "df_cora_sgc_merged.groupby(\"strategy\")[\"diff\"].max().reset_index().sort_values(\"diff\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined, df = create_df(all_metrics[(\"cora_ml\", \"gcn\")])\n",
    "# df_combined.to_csv(\"../other_data/cora_ml_gcn.csv\")\n",
    "df_combined = pd.read_csv(\"../other_data/cora_ml_gcn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[df_combined.index.str.contains(\"tta_expected_query_score_aleatoric_propagated_fmask_emask_100_nofilter_0.5_0.4\") | (df_combined.index.str.contains(\"aleatoric_propagated_fmask_emask_100_filter\") & df_combined.index.str.contains(\"_0.5_0.4\") & ~df_combined.index.str.contains(\"educated\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = df_combined[df_combined.index.str.contains(\"latent\")].copy()\n",
    "latent_df[\"p_f\"] = latent_df.index.map(lambda x: x.split(\"_\")[4]).astype(float)\n",
    "latent_df[\"p_e\"] = np.nan\n",
    "latent_df[\"m_f\"] = \"latent\"\n",
    "latent_df[\"m_e\"] = \"none\"\n",
    "latent_df[\"num\"] = 100\n",
    "latent_df[\"filter\"] = latent_df.index.map(lambda x: \"filter\" if x.split(\"_\")[-1] == \"filter\" else \"nofilter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_mean</th>\n",
       "      <th>5_mean</th>\n",
       "      <th>10_mean</th>\n",
       "      <th>15_mean</th>\n",
       "      <th>20_mean</th>\n",
       "      <th>28_mean</th>\n",
       "      <th>0_std</th>\n",
       "      <th>5_std</th>\n",
       "      <th>10_std</th>\n",
       "      <th>15_std</th>\n",
       "      <th>20_std</th>\n",
       "      <th>28_std</th>\n",
       "      <th>0_mean_formatted</th>\n",
       "      <th>5_mean_formatted</th>\n",
       "      <th>10_mean_formatted</th>\n",
       "      <th>15_mean_formatted</th>\n",
       "      <th>20_mean_formatted</th>\n",
       "      <th>28_mean_formatted</th>\n",
       "      <th>nalc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_200_filter_probs_0.5_0.4</th>\n",
       "      <td>39.007143</td>\n",
       "      <td>53.192857</td>\n",
       "      <td>65.707143</td>\n",
       "      <td>72.014286</td>\n",
       "      <td>75.335714</td>\n",
       "      <td>78.800000</td>\n",
       "      <td>12.367675</td>\n",
       "      <td>13.331557</td>\n",
       "      <td>9.087090</td>\n",
       "      <td>6.501083</td>\n",
       "      <td>4.349326</td>\n",
       "      <td>2.427793</td>\n",
       "      <td>39.0 ± 12.4</td>\n",
       "      <td>53.2 ± 13.3</td>\n",
       "      <td>65.7 ± 9.1</td>\n",
       "      <td>72.0 ± 6.5</td>\n",
       "      <td>75.3 ± 4.3</td>\n",
       "      <td>78.8 ± 2.4</td>\n",
       "      <td>92.010621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_2000_filter_probs_0.5_0.4</th>\n",
       "      <td>39.514286</td>\n",
       "      <td>54.614286</td>\n",
       "      <td>67.185714</td>\n",
       "      <td>71.478571</td>\n",
       "      <td>75.128572</td>\n",
       "      <td>78.778572</td>\n",
       "      <td>11.199322</td>\n",
       "      <td>13.443730</td>\n",
       "      <td>10.446569</td>\n",
       "      <td>6.466658</td>\n",
       "      <td>4.797830</td>\n",
       "      <td>3.252817</td>\n",
       "      <td>39.5 ± 11.2</td>\n",
       "      <td>54.6 ± 13.4</td>\n",
       "      <td>67.2 ± 10.4</td>\n",
       "      <td>71.5 ± 6.5</td>\n",
       "      <td>75.1 ± 4.8</td>\n",
       "      <td>78.8 ± 3.3</td>\n",
       "      <td>92.219646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.5_0.4</th>\n",
       "      <td>41.078571</td>\n",
       "      <td>55.100000</td>\n",
       "      <td>63.614286</td>\n",
       "      <td>70.907142</td>\n",
       "      <td>76.307143</td>\n",
       "      <td>78.221429</td>\n",
       "      <td>14.290131</td>\n",
       "      <td>16.042123</td>\n",
       "      <td>11.786394</td>\n",
       "      <td>5.650520</td>\n",
       "      <td>2.885450</td>\n",
       "      <td>2.868495</td>\n",
       "      <td>41.1 ± 14.3</td>\n",
       "      <td>55.1 ± 16.0</td>\n",
       "      <td>63.6 ± 11.8</td>\n",
       "      <td>70.9 ± 5.7</td>\n",
       "      <td>76.3 ± 2.9</td>\n",
       "      <td>78.2 ± 2.9</td>\n",
       "      <td>91.849208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_emask_100_filter_probs_0.4_0.3</th>\n",
       "      <td>40.607143</td>\n",
       "      <td>57.064285</td>\n",
       "      <td>68.021428</td>\n",
       "      <td>73.200000</td>\n",
       "      <td>74.585715</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>13.315826</td>\n",
       "      <td>10.024597</td>\n",
       "      <td>7.860538</td>\n",
       "      <td>5.478837</td>\n",
       "      <td>4.126111</td>\n",
       "      <td>3.057693</td>\n",
       "      <td>40.6 ± 13.3</td>\n",
       "      <td>57.1 ± 10.0</td>\n",
       "      <td>68.0 ± 7.9</td>\n",
       "      <td>73.2 ± 5.5</td>\n",
       "      <td>74.6 ± 4.1</td>\n",
       "      <td>78.1 ± 3.1</td>\n",
       "      <td>93.356506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.5_0.5</th>\n",
       "      <td>41.092857</td>\n",
       "      <td>54.800000</td>\n",
       "      <td>65.207143</td>\n",
       "      <td>71.542857</td>\n",
       "      <td>74.985715</td>\n",
       "      <td>78.057143</td>\n",
       "      <td>15.236764</td>\n",
       "      <td>12.506357</td>\n",
       "      <td>8.654314</td>\n",
       "      <td>6.718061</td>\n",
       "      <td>3.904119</td>\n",
       "      <td>2.907731</td>\n",
       "      <td>41.1 ± 15.2</td>\n",
       "      <td>54.8 ± 12.5</td>\n",
       "      <td>65.2 ± 8.7</td>\n",
       "      <td>71.5 ± 6.7</td>\n",
       "      <td>75.0 ± 3.9</td>\n",
       "      <td>78.1 ± 2.9</td>\n",
       "      <td>91.907270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_enone_100_nofilter_probs_0.8_none</th>\n",
       "      <td>41.521428</td>\n",
       "      <td>49.585715</td>\n",
       "      <td>57.821429</td>\n",
       "      <td>62.385715</td>\n",
       "      <td>67.942858</td>\n",
       "      <td>73.407143</td>\n",
       "      <td>13.969730</td>\n",
       "      <td>13.898294</td>\n",
       "      <td>12.119516</td>\n",
       "      <td>10.356266</td>\n",
       "      <td>8.255660</td>\n",
       "      <td>5.537654</td>\n",
       "      <td>41.5 ± 14.0</td>\n",
       "      <td>49.6 ± 13.9</td>\n",
       "      <td>57.8 ± 12.1</td>\n",
       "      <td>62.4 ± 10.4</td>\n",
       "      <td>67.9 ± 8.3</td>\n",
       "      <td>73.4 ± 5.5</td>\n",
       "      <td>83.806412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_enone_100_nofilter_probs_0.2_none</th>\n",
       "      <td>39.892857</td>\n",
       "      <td>54.450000</td>\n",
       "      <td>61.950000</td>\n",
       "      <td>67.357143</td>\n",
       "      <td>70.192857</td>\n",
       "      <td>73.400000</td>\n",
       "      <td>14.458597</td>\n",
       "      <td>13.277159</td>\n",
       "      <td>10.697239</td>\n",
       "      <td>6.110380</td>\n",
       "      <td>6.908646</td>\n",
       "      <td>4.264076</td>\n",
       "      <td>39.9 ± 14.5</td>\n",
       "      <td>54.4 ± 13.3</td>\n",
       "      <td>62.0 ± 10.7</td>\n",
       "      <td>67.4 ± 6.1</td>\n",
       "      <td>70.2 ± 6.9</td>\n",
       "      <td>73.4 ± 4.3</td>\n",
       "      <td>86.377026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_enone_100_nofilter_probs_0.8_none</th>\n",
       "      <td>38.871429</td>\n",
       "      <td>54.357143</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>65.935714</td>\n",
       "      <td>69.178572</td>\n",
       "      <td>72.592857</td>\n",
       "      <td>13.100838</td>\n",
       "      <td>12.191813</td>\n",
       "      <td>10.054698</td>\n",
       "      <td>8.502443</td>\n",
       "      <td>7.586575</td>\n",
       "      <td>7.167123</td>\n",
       "      <td>38.9 ± 13.1</td>\n",
       "      <td>54.4 ± 12.2</td>\n",
       "      <td>60.5 ± 10.1</td>\n",
       "      <td>65.9 ± 8.5</td>\n",
       "      <td>69.2 ± 7.6</td>\n",
       "      <td>72.6 ± 7.2</td>\n",
       "      <td>86.383219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnone_emask_100_filter_probs_none_0.05</th>\n",
       "      <td>40.657143</td>\n",
       "      <td>48.707143</td>\n",
       "      <td>58.478572</td>\n",
       "      <td>66.271429</td>\n",
       "      <td>69.178571</td>\n",
       "      <td>72.292857</td>\n",
       "      <td>14.346898</td>\n",
       "      <td>14.019964</td>\n",
       "      <td>13.611981</td>\n",
       "      <td>9.485666</td>\n",
       "      <td>7.290440</td>\n",
       "      <td>6.161243</td>\n",
       "      <td>40.7 ± 14.3</td>\n",
       "      <td>48.7 ± 14.0</td>\n",
       "      <td>58.5 ± 13.6</td>\n",
       "      <td>66.3 ± 9.5</td>\n",
       "      <td>69.2 ± 7.3</td>\n",
       "      <td>72.3 ± 6.2</td>\n",
       "      <td>84.633607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_enone_100_nofilter_probs_0.9_none</th>\n",
       "      <td>39.350001</td>\n",
       "      <td>53.421428</td>\n",
       "      <td>58.785715</td>\n",
       "      <td>62.878572</td>\n",
       "      <td>66.292857</td>\n",
       "      <td>70.107142</td>\n",
       "      <td>13.873415</td>\n",
       "      <td>11.739051</td>\n",
       "      <td>11.229971</td>\n",
       "      <td>10.343134</td>\n",
       "      <td>7.950786</td>\n",
       "      <td>7.143571</td>\n",
       "      <td>39.4 ± 13.9</td>\n",
       "      <td>53.4 ± 11.7</td>\n",
       "      <td>58.8 ± 11.2</td>\n",
       "      <td>62.9 ± 10.3</td>\n",
       "      <td>66.3 ± 8.0</td>\n",
       "      <td>70.1 ± 7.1</td>\n",
       "      <td>82.390465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0_mean     5_mean  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  39.007143  53.192857   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  39.514286  54.614286   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  41.078571  55.100000   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  40.607143  57.064285   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  41.092857  54.800000   \n",
       "...                                                       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  41.521428  49.585715   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  39.892857  54.450000   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  38.871429  54.357143   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  40.657143  48.707143   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  39.350001  53.421428   \n",
       "\n",
       "                                                      10_mean    15_mean  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  65.707143  72.014286   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  67.185714  71.478571   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  63.614286  70.907142   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  68.021428  73.200000   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  65.207143  71.542857   \n",
       "...                                                       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  57.821429  62.385715   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  61.950000  67.357143   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  60.500000  65.935714   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  58.478572  66.271429   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  58.785715  62.878572   \n",
       "\n",
       "                                                      20_mean    28_mean  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  75.335714  78.800000   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  75.128572  78.778572   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  76.307143  78.221429   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  74.585715  78.142857   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  74.985715  78.057143   \n",
       "...                                                       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  67.942858  73.407143   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  70.192857  73.400000   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  69.178572  72.592857   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  69.178571  72.292857   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  66.292857  70.107142   \n",
       "\n",
       "                                                        0_std      5_std  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  12.367675  13.331557   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  11.199322  13.443730   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  14.290131  16.042123   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  13.315826  10.024597   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  15.236764  12.506357   \n",
       "...                                                       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  13.969730  13.898294   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  14.458597  13.277159   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  13.100838  12.191813   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  14.346898  14.019964   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  13.873415  11.739051   \n",
       "\n",
       "                                                       10_std     15_std  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...   9.087090   6.501083   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  10.446569   6.466658   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  11.786394   5.650520   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...   7.860538   5.478837   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...   8.654314   6.718061   \n",
       "...                                                       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  12.119516  10.356266   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  10.697239   6.110380   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  10.054698   8.502443   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  13.611981   9.485666   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  11.229971  10.343134   \n",
       "\n",
       "                                                      20_std    28_std  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  4.349326  2.427793   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  4.797830  3.252817   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  2.885450  2.868495   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  4.126111  3.057693   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  3.904119  2.907731   \n",
       "...                                                      ...       ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  8.255660  5.537654   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  6.908646  4.264076   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  7.586575  7.167123   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  7.290440  6.161243   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  7.950786  7.143571   \n",
       "\n",
       "                                                   0_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...      39.0 ± 12.4   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...      39.5 ± 11.2   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...      41.1 ± 14.3   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...      40.6 ± 13.3   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...      41.1 ± 15.2   \n",
       "...                                                             ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...      41.5 ± 14.0   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...      39.9 ± 14.5   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...      38.9 ± 13.1   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...      40.7 ± 14.3   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...      39.4 ± 13.9   \n",
       "\n",
       "                                                   5_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...      53.2 ± 13.3   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...      54.6 ± 13.4   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...      55.1 ± 16.0   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...      57.1 ± 10.0   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...      54.8 ± 12.5   \n",
       "...                                                             ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...      49.6 ± 13.9   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...      54.4 ± 13.3   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...      54.4 ± 12.2   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...      48.7 ± 14.0   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...      53.4 ± 11.7   \n",
       "\n",
       "                                                   10_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...        65.7 ± 9.1   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...       67.2 ± 10.4   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...       63.6 ± 11.8   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...        68.0 ± 7.9   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        65.2 ± 8.7   \n",
       "...                                                              ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...       57.8 ± 12.1   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...       62.0 ± 10.7   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...       60.5 ± 10.1   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...       58.5 ± 13.6   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...       58.8 ± 11.2   \n",
       "\n",
       "                                                   15_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...        72.0 ± 6.5   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...        71.5 ± 6.5   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        70.9 ± 5.7   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...        73.2 ± 5.5   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        71.5 ± 6.7   \n",
       "...                                                              ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...       62.4 ± 10.4   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        67.4 ± 6.1   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        65.9 ± 8.5   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...        66.3 ± 9.5   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...       62.9 ± 10.3   \n",
       "\n",
       "                                                   20_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...        75.3 ± 4.3   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...        75.1 ± 4.8   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        76.3 ± 2.9   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...        74.6 ± 4.1   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        75.0 ± 3.9   \n",
       "...                                                              ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...        67.9 ± 8.3   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        70.2 ± 6.9   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        69.2 ± 7.6   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...        69.2 ± 7.3   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...        66.3 ± 8.0   \n",
       "\n",
       "                                                   28_mean_formatted  \\\n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...        78.8 ± 2.4   \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...        78.8 ± 3.3   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        78.2 ± 2.9   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...        78.1 ± 3.1   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...        78.1 ± 2.9   \n",
       "...                                                              ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...        73.4 ± 5.5   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        73.4 ± 4.3   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...        72.6 ± 7.2   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...        72.3 ± 6.2   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...        70.1 ± 7.1   \n",
       "\n",
       "                                                         nalc  \n",
       "aleatoric_propagated_fmask_emask_200_filter_pro...  92.010621  \n",
       "aleatoric_propagated_fmask_emask_2000_filter_pr...  92.219646  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  91.849208  \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  93.356506  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  91.907270  \n",
       "...                                                       ...  \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  83.806412  \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  86.377026  \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  86.383219  \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  84.633607  \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  82.390465  \n",
       "\n",
       "[180 rows x 19 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[df_combined.index.str.contains(\"aleatoric_propagated\")& df_combined.index.str.contains(\"probs_\")& ~df_combined.index.str.contains(\"educated_random\")& ~df_combined.index.str.contains(\"test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_e</th>\n",
       "      <th>p_f</th>\n",
       "      <th>m_e</th>\n",
       "      <th>m_f</th>\n",
       "      <th>num</th>\n",
       "      <th>filter</th>\n",
       "      <th>28_mean</th>\n",
       "      <th>28_std</th>\n",
       "      <th>nalc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.5_0.4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mask</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>78.221429</td>\n",
       "      <td>2.868495</td>\n",
       "      <td>91.849208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_emask_100_filter_probs_0.4_0.3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>mask</td>\n",
       "      <td>noise</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>3.057693</td>\n",
       "      <td>93.356506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.5_0.5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mask</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>78.057143</td>\n",
       "      <td>2.907731</td>\n",
       "      <td>91.907270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.3_0.2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>mask</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>77.878572</td>\n",
       "      <td>2.580500</td>\n",
       "      <td>90.070178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_emask_100_filter_probs_0.4_0.3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>mask</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>77.785714</td>\n",
       "      <td>2.487213</td>\n",
       "      <td>90.128627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_enone_100_nofilter_probs_0.8_none</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>none</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>nofilter</td>\n",
       "      <td>73.407143</td>\n",
       "      <td>5.537654</td>\n",
       "      <td>83.806412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_enone_100_nofilter_probs_0.2_none</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>none</td>\n",
       "      <td>noise</td>\n",
       "      <td>100</td>\n",
       "      <td>nofilter</td>\n",
       "      <td>73.400000</td>\n",
       "      <td>4.264076</td>\n",
       "      <td>86.377026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnoise_enone_100_nofilter_probs_0.8_none</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>none</td>\n",
       "      <td>noise</td>\n",
       "      <td>100</td>\n",
       "      <td>nofilter</td>\n",
       "      <td>72.592857</td>\n",
       "      <td>7.167123</td>\n",
       "      <td>86.383219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fnone_emask_100_filter_probs_none_0.05</th>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mask</td>\n",
       "      <td>none</td>\n",
       "      <td>100</td>\n",
       "      <td>filter</td>\n",
       "      <td>72.292857</td>\n",
       "      <td>6.161243</td>\n",
       "      <td>84.633607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aleatoric_propagated_fmask_enone_100_nofilter_probs_0.9_none</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>none</td>\n",
       "      <td>mask</td>\n",
       "      <td>100</td>\n",
       "      <td>nofilter</td>\n",
       "      <td>70.107142</td>\n",
       "      <td>7.143571</td>\n",
       "      <td>82.390465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     p_e  p_f   m_e    m_f  \\\n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  0.40  0.5  mask   mask   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  0.30  0.4  mask  noise   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  0.50  0.5  mask   mask   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  0.20  0.3  mask   mask   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  0.30  0.4  mask   mask   \n",
       "...                                                  ...  ...   ...    ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...   NaN  0.8  none   mask   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...   NaN  0.2  none  noise   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...   NaN  0.8  none  noise   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  0.05  NaN  mask   none   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...   NaN  0.9  none   mask   \n",
       "\n",
       "                                                    num    filter    28_mean  \\\n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  100    filter  78.221429   \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  100    filter  78.142857   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  100    filter  78.057143   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  100    filter  77.878572   \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  100    filter  77.785714   \n",
       "...                                                 ...       ...        ...   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  100  nofilter  73.407143   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  100  nofilter  73.400000   \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  100  nofilter  72.592857   \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  100    filter  72.292857   \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  100  nofilter  70.107142   \n",
       "\n",
       "                                                      28_std       nalc  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  2.868495  91.849208  \n",
       "aleatoric_propagated_fnoise_emask_100_filter_pr...  3.057693  93.356506  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  2.907731  91.907270  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  2.580500  90.070178  \n",
       "aleatoric_propagated_fmask_emask_100_filter_pro...  2.487213  90.128627  \n",
       "...                                                      ...        ...  \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  5.537654  83.806412  \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  4.264076  86.377026  \n",
       "aleatoric_propagated_fnoise_enone_100_nofilter_...  7.167123  86.383219  \n",
       "aleatoric_propagated_fnone_emask_100_filter_pro...  6.161243  84.633607  \n",
       "aleatoric_propagated_fmask_enone_100_nofilter_p...  7.143571  82.390465  \n",
       "\n",
       "[189 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_df = df_combined[df_combined.index.str.contains(\"aleatoric_propagated\")& df_combined.index.str.contains(\"probs_\") & ~df_combined.index.str.contains(\"educated_random\") & ~df_combined.index.str.contains(\"test\") ].copy()\n",
    "tta_df = process_tta(tta_df)\n",
    "tta_df = pd.concat([latent_df, tta_df], axis=0)\n",
    "tta_df = tta_df[[\"p_e\",\"p_f\",\"m_e\",\"m_f\",\"num\",\"filter\",\"28_mean\", \"28_std\", \"nalc\"]]\n",
    "tta_df_orig = tta_df.copy()\n",
    "tta_df = tta_df[tta_df[\"num\"] == 100]\n",
    "tta_df_filter = tta_df[tta_df[\"filter\"] == \"filter\"]  \n",
    "tta_df_no_filter = tta_df[tta_df[\"filter\"] == \"nofilter\"]\n",
    "tta_df_merged = pd.merge(tta_df_filter, tta_df_no_filter, on=[\"p_e\",\"p_f\",\"m_e\",\"m_f\", \"num\"], suffixes=(\"_filter\", \"_no_filter\"), how=\"right\")\n",
    "tta_df_merged[\"mean_diff\"] = tta_df_merged[\"28_mean_filter\"] - tta_df_merged[\"28_mean_no_filter\"]\n",
    "tta_df_merged[\"std_diff\"] = tta_df_merged[\"28_std_filter\"] - tta_df_merged[\"28_std_no_filter\"]\n",
    "tta_df_merged.sort_values(by=\"mean_diff\", ascending=False, inplace=True)\n",
    "tta_df_merged.reset_index(drop=True, inplace=True)\n",
    "tta_df_merged.drop(columns=[\"filter_filter\",\"filter_no_filter\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_df_merged_separate = tta_df_merged[(tta_df_merged[\"p_e\"].isna()) | (tta_df_merged[\"p_f\"].isna())].copy()\n",
    "tta_df_merged_separate[\"type\"] = tta_df_merged_separate.apply(lambda x: \"e\" + x[\"m_e\"] if x[\"m_e\"] != \"none\" else \"f\" + x[\"m_f\"], axis=1)\n",
    "tta_df_merged_separate[\"level\"] = tta_df_merged_separate.apply(lambda x: x[\"p_f\"] if not pd.isna(x[\"p_f\"]) else x[\"p_e\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = tta_df_merged_separate.pivot(index=\"level\", columns=\"type\", values=\"28_mean_filter\")\n",
    "pivot_table.sort_index(axis=0, ascending=False, inplace=True)\n",
    "pivot_table.rename(columns={\"emask\": \"Edge\\nmasking\", \"fmask\": \"Feature\\nmasking\", \"fnoise\": \"Feature\\nnoising\", \"flatent\": \"Latent\\nnoising\"}, inplace=True)\n",
    "pivot_table = pivot_table[[\"Edge\\nmasking\", \"Feature\\nmasking\", \"Feature\\nnoising\", \"Latent\\nnoising\"]]\n",
    "ma = pivot_table.max().max()\n",
    "mi = pivot_table.min().min()\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=mi, vmax=ma)\n",
    "plt.title(\"Accuracies by \\n Filtered augmentations\")\n",
    "plt.xlabel(\"Augmentation type\")\n",
    "plt.ylabel(\"Augmentation strength\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = tta_df_merged_separate.pivot(index=\"level\", columns=\"type\", values=\"28_mean_no_filter\")\n",
    "pivot_table.sort_index(axis=0, ascending=False, inplace=True)\n",
    "pivot_table.rename(columns={\"emask\": \"Edge\\nmasking\", \"fmask\": \"Feature\\nmasking\", \"fnoise\": \"Feature\\nnoising\", \"flatent\": \"Latent\\nnoising\"}, inplace=True)\n",
    "pivot_table = pivot_table[[\"Edge\\nmasking\", \"Feature\\nmasking\", \"Feature\\nnoising\", \"Latent\\nnoising\"]]\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=mi, vmax=ma)\n",
    "plt.title(\"Accuracies by\\nAugmentations\")\n",
    "plt.xlabel(\"Augmentation type\")\n",
    "plt.ylabel(\"Augmentation strength\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = tta_df_merged_separate.pivot(index=\"level\", columns=\"type\", values=\"mean_diff\")\n",
    "pivot_table.sort_index(axis=0, ascending=False, inplace=True)\n",
    "pivot_table.rename(columns={\"emask\": \"Edge\\nmasking\", \"fmask\": \"Feature\\nmasking\", \"fnoise\": \"Feature\\nnoising\", \"flatent\": \"Latent\\nnoising\"}, inplace=True)\n",
    "pivot_table = pivot_table[[\"Edge\\nmasking\", \"Feature\\nmasking\", \"Feature\\nnoising\", \"Latent\\nnoising\"]]\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Accuracy difference\")\n",
    "plt.xlabel(\"Augmentation type\")\n",
    "plt.ylabel(\"Augmentation strength\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "# tta_df_merged_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_df_merged_combined_mask = tta_df_merged[~tta_df_merged[\"p_e\"].isna() & ~tta_df_merged[\"p_f\"].isna() & (tta_df_merged[\"m_f\"] == \"mask\")].copy()\n",
    "pivot_table_mask = tta_df_merged_combined_mask.pivot(index=\"p_f\", columns=\"p_e\", values=\"28_mean_no_filter\")\n",
    "pivot_table_mask.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "tta_combined_hyperparam_noise = tta_df_merged[~tta_df_merged[\"p_e\"].isna() & ~tta_df_merged[\"p_f\"].isna() & (tta_df_merged[\"m_f\"] == \"noise\")].copy()\n",
    "pivot_table_noise = tta_combined_hyperparam_noise.pivot(index='p_f', columns='p_e', values='28_mean_no_filter')\n",
    "pivot_table_noise.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "pivot_table_mask_filter = tta_df_merged_combined_mask.pivot(index=\"p_f\", columns=\"p_e\", values=\"28_mean_filter\")\n",
    "pivot_table_mask_filter.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "pivot_table_noise_filter = tta_combined_hyperparam_noise.pivot(index='p_f', columns='p_e', values='28_mean_filter')\n",
    "pivot_table_noise_filter.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "pivot_table_mask_diff = tta_df_merged_combined_mask.pivot(index=\"p_f\", columns=\"p_e\", values=\"mean_diff\")\n",
    "pivot_table_mask_diff.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "pivot_table_noise_diff = tta_combined_hyperparam_noise.pivot(index='p_f', columns='p_e', values='mean_diff')\n",
    "pivot_table_noise_diff.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "mask_max = max(pivot_table_mask.max().max(), pivot_table_mask_filter.max().max())\n",
    "mask_min = min(pivot_table_mask.min().min(), pivot_table_mask_filter.min().min())\n",
    "noise_max = max(pivot_table_noise.max().max(), pivot_table_noise_filter.max().max())\n",
    "noise_min = min(pivot_table_noise.min().min(), pivot_table_noise_filter.min().min())\n",
    "\n",
    "min_min = min(mask_min, noise_min)\n",
    "max_max = max(mask_max, noise_max)\n",
    "\n",
    "diff_max = max(pivot_table_mask_diff.max().max(), pivot_table_noise_diff.max().max())\n",
    "diff_min = min(pivot_table_mask_diff.min().min(), pivot_table_noise_diff.min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(12, 15))\n",
    "\n",
    "# Heatmap for pivot_table_mask\n",
    "sns.heatmap(pivot_table_mask, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", ax=axs[0, 0], vmin=min_min, vmax=max_max)\n",
    "axs[0, 0].set_title(\"Accuracies by Feature Masking and Edge Dropping strength\")\n",
    "axs[0, 0].set_ylabel(\"Feature Masking Probability\")\n",
    "axs[0, 0].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "# Heatmap for pivot_table_noise\n",
    "sns.heatmap(pivot_table_noise, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", ax=axs[0, 1], vmin=min_min, vmax=max_max)\n",
    "axs[0, 1].set_title(\"Accuracies by Feature Noising and Edge Dropping strength\")\n",
    "axs[0, 1].set_ylabel(\"Feature Noising Strength\")\n",
    "axs[0, 1].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "# Heatmap for pivot_table_mask_filter\n",
    "sns.heatmap(pivot_table_mask_filter, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", ax=axs[1, 0], vmin=min_min, vmax=max_max)\n",
    "axs[1, 0].set_title(\"Accuracies by Feature Masking and Edge Dropping strength \\n Filtered\")\n",
    "axs[1, 0].set_ylabel(\"Feature Mask Probability\")\n",
    "axs[1, 0].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "# Heatmap for pivot_table_noise_filter\n",
    "sns.heatmap(pivot_table_noise_filter, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", ax=axs[1, 1], vmin=min_min, vmax=max_max)\n",
    "axs[1, 1].set_title(\"Accuracies by Feature Noising and Edge Dropping strength \\n Filtered\")\n",
    "axs[1, 1].set_ylabel(\"Feature Noising Strength\")\n",
    "axs[1, 1].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "\n",
    "# Heatmap for pivot_table_mask_diff\n",
    "sns.heatmap(pivot_table_mask_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=axs[2, 0], center=0, vmin=diff_min, vmax=diff_max)\n",
    "axs[2, 0].set_title(\"Mean Difference by Feature Masking and Edge Dropping strength\")\n",
    "axs[2, 0].set_ylabel(\"Feature Mask Probability\")\n",
    "axs[2, 0].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "# Heatmap for pivot_table_noise_diff\n",
    "sns.heatmap(pivot_table_noise_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=axs[2, 1], center=0, vmin=diff_min, vmax=diff_max)\n",
    "axs[2, 1].set_title(\"Mean Difference by Feature Noising and Edge Dropping strength\")\n",
    "axs[2, 1].set_ylabel(\"Feature Noising Strength\")\n",
    "axs[2, 1].set_xlabel(\"Edge Dropping Probability\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot_table_mask, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",  vmin=min_min, vmax=max_max)\n",
    "plt.title(\"Accuracies by Feature Masking and Edge Dropping strength\")\n",
    "plt.ylabel(\"Feature Masking Probability\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot_table_noise, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",  vmin=min_min, vmax=max_max)\n",
    "plt.title(\"Accuracies by Feature Noising and Edge Dropping strength\")\n",
    "plt.ylabel(\"Feature Noising Strength\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot_table_mask_filter, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",  vmin=min_min, vmax=max_max)\n",
    "plt.title(\"Accuracies by Feature Masking and Edge Dropping strength \\n Filtered\")\n",
    "plt.ylabel(\"Feature Mask Probability\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot_table_noise_filter, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",  vmin=min_min, vmax=max_max)\n",
    "plt.title(\"Accuracies by Feature Noising and Edge Dropping strength \\n Filtered\")\n",
    "plt.ylabel(\"Feature Noising Strength\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for pivot_table_mask_diff\n",
    "sns.heatmap(pivot_table_mask_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\",  center=0, vmin=diff_min, vmax=diff_max)\n",
    "plt.title(\"Mean Difference by Feature Masking and Edge Dropping strength\")\n",
    "plt.ylabel(\"Feature Mask Probability\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for pivot_table_noise_diff\n",
    "sns.heatmap(pivot_table_noise_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\",  center=0, vmin=diff_min, vmax=diff_max)\n",
    "plt.title(\"Mean Difference by Feature Noising and Edge Dropping strength\")\n",
    "plt.ylabel(\"Feature Noising Strength\")\n",
    "plt.xlabel(\"Edge Dropping Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_num = tta_df_orig[(tta_df_orig[\"p_e\"] == 0.4) & (tta_df_orig[\"p_f\"] == 0.5) & (tta_df_orig[\"m_f\"] == \"mask\") & (tta_df_orig[\"m_e\"] == \"mask\") & (tta_df_orig[\"filter\"] == \"filter\")].copy()\n",
    "tta_num.sort_values(by=\"num\", inplace=True)\n",
    "ax = tta_num.plot(x=\"num\", y=\"28_mean\", marker='o', figsize=(8, 4), title=\"Sensitivity to the number of augmented views\")\n",
    "ax.legend().set_visible(False)  # Hide the legend\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Number of augmented views\")\n",
    "plt.title(\"Sensitivity to the number of augmented views\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract adaptation mode, learning rate, and number of epochs from the index\n",
    "df_adapted = df_combined[df_combined.index.str.contains(\"feature\") | df_combined.index.str.contains(\"adj\") |df_combined.index.str.contains(\"graph\")  ]\n",
    "df_adapted = df_adapted.copy()\n",
    "df_adapted['adaptation_mode'] = df_adapted.index.str.split('_').str[2]\n",
    "# df_adapted['learning_rate'] = df_adapted.index.map(lambda x: x.split('_')[3][3:] if 'adj' in x else (x.split('_')[4][3:] if 'feature' in x else (x.split('_')[3][3:] if 'graph' in x else None)))\n",
    "df_adapted['learning_rate_adj'] = df_adapted.index.map(lambda x: x.split('_')[3][2:] if 'adj' in x else (x.split('_')[3][3:] if 'graph' in x else None))\n",
    "df_adapted['learning_rate_feature'] = df_adapted.index.map(lambda x: x.split('_')[3][2:] if 'feature' in x else (x.split('_')[4][3:] if 'graph' in x else None))\n",
    "df_adapted['epochs'] = df_adapted.index.map(lambda x: x.split('_')[4][6:] if 'graph' not in x else x.split('_')[5][6:])\n",
    "# df_adapted[\"learning_rate\"] = df_adapted[\"learning_rate\"].astype(float)\n",
    "df_adapted[\"epochs\"] = df_adapted[\"epochs\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adapted_features = df_adapted[df_adapted[\"adaptation_mode\"] == \"feature\"]\n",
    "pivot_table_feature = df_adapted_features.pivot(index=\"learning_rate_feature\", columns=\"epochs\", values=\"28_mean\")\n",
    "pivot_table_feature.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "df_adapted_structure = df_adapted[df_adapted[\"adaptation_mode\"] == \"adj\"]\n",
    "pivot_table_structure = df_adapted_structure.pivot(index=\"learning_rate_adj\", columns=\"epochs\", values=\"28_mean\")\n",
    "pivot_table_structure.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "vmin = min(pivot_table_feature.min().min(), pivot_table_structure.min().min())\n",
    "vmax = max(pivot_table_feature.max().max(), pivot_table_structure.max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(pivot_table_feature, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Feature Adaptation \\n Accuracies by Learning Rate and Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(pivot_table_structure, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Structure Adaptation \\n Accuracies by Learning Rate and Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_adapted_graph = df_adapted[df_adapted[\"adaptation_mode\"] == \"graph\"]\n",
    "df_adapted_graph = df_adapted_graph.copy()\n",
    "le_adj, le_feature = LabelEncoder(), LabelEncoder()\n",
    "df_adapted_graph[\"learning_rate_feature_categorical\"] = le_feature.fit_transform(df_adapted_graph[\"learning_rate_feature\"])\n",
    "df_adapted_graph[\"learning_rate_adj_categorical\"] = le_adj.fit_transform(df_adapted_graph[\"learning_rate_adj\"])\n",
    "df_adapted_graph[\"epochs_to_plot\"] = df_adapted_graph[\"epochs\"]\n",
    "# Add jitter to learning_rate_feature_categorical, learning_rate_adj_categorical, and epochs\n",
    "df_adapted_graph[\"learning_rate_feature_categorical\"] = df_adapted_graph[\"learning_rate_feature_categorical\"] + np.random.uniform(-0.01, 0.01, df_adapted_graph.shape[0])\n",
    "df_adapted_graph[\"learning_rate_adj_categorical\"] = df_adapted_graph[\"learning_rate_adj_categorical\"] + np.random.uniform(-0.01, 0.01, df_adapted_graph.shape[0])\n",
    "df_adapted_graph[\"epochs_to_plot\"] = df_adapted_graph[\"epochs_to_plot\"] + np.random.uniform(-0.1, 0.1, df_adapted_graph.shape[0])\n",
    "import plotly.express as px\n",
    "df_adapted_graph.sort_values(by=\"28_mean\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adapted_graph_cp = df_adapted_graph.copy()\n",
    "df_adapted_graph_cp.rename(columns={\"28_mean\": \"accuracy\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assume df has columns: learning_rate1, learning_rate2, epochs, accuracy\n",
    "model = ols('accuracy ~ C(learning_rate_feature) + C(learning_rate_adj) + C(epochs)', data=df_adapted_graph_cp).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Boxplot for learning_rate_feature\n",
    "sns.boxplot(x=\"learning_rate_feature\", y=\"28_mean\", data=df_adapted_graph, ax=axes[0])\n",
    "axes[0].set_title(\"Boxplot of Accuracies by Learning Rate (Feature)\")\n",
    "axes[0].set_xlabel(\"Learning Rate (Feature)\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Boxplot for learning_rate_adj\n",
    "sns.boxplot(x=\"learning_rate_adj\", y=\"28_mean\", data=df_adapted_graph, ax=axes[1])\n",
    "axes[1].set_title(\"Boxplot of Accuracies by Learning Rate (Adj)\")\n",
    "axes[1].set_xlabel(\"Learning Rate (Adj)\")\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Boxplot for epochs\n",
    "sns.boxplot(x=\"epochs\", y=\"28_mean\", data=df_adapted_graph, ax=axes[2])\n",
    "axes[2].set_title(\"Boxplot of Accuracies by Epochs\")\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviations grouped by different parameters\n",
    "std_learning_rate_feature = df_adapted_graph.groupby([\"learning_rate_feature\"])[\"28_mean\"].std().mean()\n",
    "std_learning_rate_adj = df_adapted_graph.groupby([\"learning_rate_adj\"])[\"28_mean\"].std().mean()\n",
    "std_epochs = df_adapted_graph.groupby([\"epochs\"])[\"28_mean\"].std().mean()\n",
    "\n",
    "# Collect results into a single DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Parameter\": [\"learning_rate_feature\", \"learning_rate_adj\", \"epochs\"],\n",
    "    \"Mean_Std\": [std_learning_rate_feature, std_learning_rate_adj, std_epochs]\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adapted_graph_filtered = df_adapted_graph[df_adapted_graph[\"learning_rate_feature\"] == \"0.001\"]\n",
    "pivot_table_graph = df_adapted_graph_filtered.pivot(index=\"learning_rate_adj\", columns=\"epochs\", values=\"28_mean\")\n",
    "pivot_table_graph.sort_index(axis=0, ascending=False, inplace=True)\n",
    "sns.heatmap(pivot_table_graph, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Graph Adaptation (Feature LR = 0.001) \\n Accuracies by Structure LR and Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Structure Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adapted_graph_filtered = df_adapted_graph[df_adapted_graph[\"learning_rate_feature\"] == \"0.0001\"]\n",
    "pivot_table_graph = df_adapted_graph_filtered.pivot(index=\"learning_rate_adj\", columns=\"epochs\", values=\"28_mean\")\n",
    "pivot_table_graph.sort_index(axis=0, ascending=False, inplace=True)\n",
    "sns.heatmap(pivot_table_graph, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Graph Adaptation (Feature LR = 0.0001) \\n Accuracies by Structure LR and Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Structure Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adapted_graph_filtered = df_adapted_graph[df_adapted_graph[\"learning_rate_feature\"] == \"0.01\"]\n",
    "pivot_table_graph = df_adapted_graph_filtered.pivot(index=\"learning_rate_adj\", columns=\"epochs\", values=\"28_mean\")\n",
    "pivot_table_graph.sort_index(axis=0, ascending=False, inplace=True)\n",
    "sns.heatmap(pivot_table_graph, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin, vmax=vmax)\n",
    "plt.title(\"Graph Adaptation (Feature LR = 0.01) \\n Accuracies by Structure LR and Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Structure Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "to_plot = df_adapted_graph\n",
    "constraint_range_min = to_plot.iloc[9][\"28_mean\"]\n",
    "constraint_range_max = to_plot.iloc[0][\"28_mean\"]\n",
    "custom_colorscale = [\n",
    "    [0.0, \"darkblue\"],   # Very low values\n",
    "    [0.2, \"blue\"],       # Low values\n",
    "    [0.4, \"lightblue\"],  # Mid-low values\n",
    "    [0.6, \"green\"],      # Mid values\n",
    "    [0.725, \"lime\"],\n",
    "    [0.85, \"yellow\"],     # High values\n",
    "    [1.0, \"red\"],        # Top values\n",
    "]\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Parcoords(\n",
    "        line=dict(\n",
    "            color=to_plot[\"28_mean\"],\n",
    "            colorscale=custom_colorscale,\n",
    "            showscale=True,  # Add this line to display the colorbar\n",
    "            colorbar=dict(\n",
    "                title=\"Mean Accuracy\"  # Title for the colorbar\n",
    "            ),\n",
    "        ),\n",
    "        dimensions=[\n",
    "            {\n",
    "                \"label\": \"Learning Rate Adj\",\n",
    "                \"values\": to_plot[\"learning_rate_adj_categorical\"],\n",
    "                \"tickvals\": le_adj.transform(le_adj.classes_),\n",
    "                \"ticktext\": le_adj.classes_,\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"label\": \"Learning Rate Feature\",\n",
    "                \"values\": to_plot[\"learning_rate_feature_categorical\"],\n",
    "                \"tickvals\": le_feature.transform(le_feature.classes_),\n",
    "                \"ticktext\": le_feature.classes_,\n",
    "                \"range\": [0, len(le_feature.classes_)-1],\n",
    "            },\n",
    "            \n",
    "            {\"label\": \"Epochs\",\n",
    "             \"values\": to_plot[\"epochs_to_plot\"],\n",
    "             \"tickvals\": np.unique(to_plot[\"epochs\"]),\n",
    "             \"ticktext\": np.unique(to_plot[\"epochs\"])},\n",
    "            {\"label\": \"Mean Accuracy\",\n",
    "             \"values\": to_plot[\"28_mean\"],\n",
    "             \"range\": [to_plot[\"28_mean\"].min(),to_plot[\"28_mean\"].max()+0.0001],\n",
    "             \"constraintrange\" : [constraint_range_min,constraint_range_max+0.0001],},\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    title=\"Combined Structure and Feature Adaptation \\n Accuracies by Learning Rate and Epoch\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educated_df = df_combined[df_combined.index.str.contains(\"educated\")].copy()\n",
    "educated_df = educated_df.drop(index=[\"educated_random_aleatoric_propagated\", \"educated_random_aleatoric_propagated_choose_first\"], errors='ignore')\n",
    "educated_df[\"top_percent\"] = educated_df.index.map(lambda x: x.split(\"_\")[-2])\n",
    "educated_df[\"top_percent\"] = educated_df[\"top_percent\"].astype(float)\n",
    "educated_df[\"low_percent\"] = educated_df.index.map(lambda x: x.split(\"_\")[-1])\n",
    "educated_df[\"low_percent\"] = educated_df[\"low_percent\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educated_df_base = educated_df[~educated_df.index.str.contains(\"probs\")].copy()\n",
    "pivot_table_educated = educated_df_base.pivot(index=\"top_percent\", columns=\"low_percent\", values=\"28_mean\")\n",
    "pivot_table_educated.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "educated_df_augmented = educated_df[educated_df.index.str.contains(\"probs\")].copy()\n",
    "pivot_table_educated_augmented = educated_df_augmented.pivot(index=\"top_percent\", columns=\"low_percent\", values=\"28_mean\")\n",
    "pivot_table_educated_augmented.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "pivot_er_diff = pivot_table_educated_augmented - pivot_table_educated \n",
    "\n",
    "er_min = min(pivot_table_educated.min().min(), pivot_table_educated_augmented.min().min())\n",
    "er_max = max(pivot_table_educated.max().max(), pivot_table_educated_augmented.max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot_er_diff, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Educated random \\nAccuracy difference\")\n",
    "plt.xlabel(\"Low Percent\")\n",
    "plt.ylabel(\"Top Percent\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(pivot_table_educated, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",vmin=er_min, vmax=er_max)\n",
    "plt.title(\"Educated random \\nMax Score strategy\")\n",
    "plt.xlabel(\"Low Percent\")\n",
    "plt.ylabel(\"Top Percent\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETTER ACCURACIES TEND TOWARD UPPER LEFT CORNER -> STRATEGY SCORES NODES CORRECTLY\n",
    "\n",
    "sns.heatmap(pivot_table_educated_augmented, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",vmin=er_min, vmax=er_max)\n",
    "plt.title(\"Educated random\\nMax Score strategy with TTA\")\n",
    "plt.xlabel(\"Low Percent\")\n",
    "plt.ylabel(\"Top Percent\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the directory that start with \"mask\"\n",
    "node_filtering = torch.load(\"../output2/runs/cora_ml/gcn/aleatoric_propagated/fmask_emask_200_filter_probs_0.5_0.4_test/2025-04-10_13-13-25_5e3a79fb-0ca8-4a4f-821d-aedfe75cb6c1/mask_filter.pt\", weights_only=True)\n",
    "p = \"../output2/runs/cora_ml/gcn/aleatoric_propagated/fmask_emask_200_filter_probs_0.5_0.4_test/2025-04-10_13-13-25_5e3a79fb-0ca8-4a4f-821d-aedfe75cb6c1/\"\n",
    "mask_file_names = [f for f in os.listdir(p) if f.startswith(\"mask\") and not f.endswith(\"filter.pt\")]\n",
    "mask_file_names.sort()\n",
    "# Print the list of mask files\n",
    "print(mask_file_names)\n",
    "mask_files = [torch.load(p + f, weights_only=True) for f in mask_file_names]\n",
    "pool_masks = torch.stack([m[\"mask_train_pool\"] for m in mask_files],dim=0)\n",
    "train_masks = torch.stack([m[\"mask_train\"] for m in mask_files],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_nodes =node_filtering.permute(0,3,1,2)[pool_masks].view(25,-1,28,200).permute(0,2,3,1)\n",
    "train_nodes =node_filtering.permute(0,3,1,2)[train_masks].view(25,-1,28,200).permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average node filtering rates\n",
    "plt.hist(node_filtering.mean(0).mean(-2).mean(0), bins=100)\n",
    "plt.show()\n",
    "node_filtering.mean(0).mean(-2).mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how different augmentations are\n",
    "plt.plot(node_filtering.mean(0).mean(-1).std(-1), label=\"Augmentation\")\n",
    "\n",
    "# how different inits are\n",
    "plt.plot(node_filtering.mean(-1).mean(-1).std(0), label=\"Init\")\n",
    "\n",
    "# how different node filter rates are \n",
    "plt.plot(node_filtering.mean(0).mean(1).std(-1), label=\"Nodes\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Example input tensor\n",
    "tensor = train_pool_nodes.mean(0).mean(1).numpy()\n",
    "num_bins = 50  # You can adjust this\n",
    "\n",
    "# Get histogram bin edges (same for all rows)\n",
    "hist_range = (np.min(tensor), np.max(tensor))\n",
    "bin_edges = np.linspace(hist_range[0], hist_range[1], num_bins + 1)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Initialize an array to hold histogram counts\n",
    "hist_counts = np.zeros((28, num_bins))\n",
    "\n",
    "# Compute histograms along axis 0 (each row)\n",
    "for i in range(28):\n",
    "    hist_counts[i], _ = np.histogram(tensor[i], bins=bin_edges)\n",
    "\n",
    "# 3D plotting\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Coordinates for bars\n",
    "_x = np.arange(28)\n",
    "_y = bin_centers\n",
    "_xx, _yy = np.meshgrid(_x, _y, indexing='ij')\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "z = np.zeros_like(x)\n",
    "dz = hist_counts.ravel()\n",
    "\n",
    "# Plot\n",
    "ax.bar3d(x, y, z, dx=0.8, dy=(bin_edges[1] - bin_edges[0]), dz=dz, shade=True)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Filtering ratio')\n",
    "ax.set_zlabel('Frequency')\n",
    "plt.title('3D Histogram (per row)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example input tensor\n",
    "tensor = train_pool_nodes.mean(0).mean(1).numpy()\n",
    "num_bins = 30\n",
    "\n",
    "\n",
    "hist_range = (np.min(tensor), np.max(tensor))\n",
    "bin_edges = np.linspace(hist_range[0], hist_range[1], num_bins + 1)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Compute histograms per row\n",
    "hist_counts = np.zeros((28, num_bins))\n",
    "for i in range(28):\n",
    "    hist_counts[i], _ = np.histogram(tensor[i], bins=bin_edges)\n",
    "\n",
    "# Compute mean for each row\n",
    "row_means = np.mean(tensor, axis=1)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(hist_counts.T, aspect='auto', origin='lower',\n",
    "           extent=[0, 27, bin_edges[0], bin_edges[-1]],\n",
    "           cmap='coolwarm')\n",
    "\n",
    "# Overlay mean line\n",
    "x_vals = np.arange(28)\n",
    "plt.plot(x_vals, row_means, color='red', linewidth=2, label='Mean')\n",
    "\n",
    "# Labels and layout\n",
    "plt.colorbar(label='Frequency')\n",
    "plt.xlabel('Row Index')\n",
    "plt.ylabel('Bin Center')\n",
    "plt.title('2D Heatmap of Histograms + Mean Line')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Example input tensor\n",
    "tensor = train_pool_nodes.mean(0).mean(1).numpy()\n",
    "num_bins = 50  # You can adjust this\n",
    "\n",
    "# Get histogram bin edges (same for all rows)\n",
    "hist_range = (np.min(tensor), np.max(tensor))\n",
    "bin_edges = np.linspace(hist_range[0], hist_range[1], num_bins + 1)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Initialize an array to hold histogram counts\n",
    "hist_counts = np.zeros((28, num_bins))\n",
    "\n",
    "# Compute histograms along axis 0 (each row)\n",
    "for i in range(28):\n",
    "    hist_counts[i], _ = np.histogram(tensor[i], bins=bin_edges)\n",
    "\n",
    "# 3D plotting\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Swapped coordinates for bars\n",
    "_x = bin_centers  # now x-axis shows histogram bins\n",
    "_y = np.arange(28)  # now y-axis shows row index\n",
    "_xx, _yy = np.meshgrid(_x, _y, indexing='ij')  # swap meshgrid axes\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "z = np.zeros_like(x)\n",
    "dz = hist_counts.T.ravel()  # transpose because we've swapped axes\n",
    "\n",
    "# Plot\n",
    "ax.bar3d(x, y, z, dx=(bin_edges[1] - bin_edges[0]), dy=0.8, dz=dz, shade=True)\n",
    "\n",
    "# Update labels accordingly\n",
    "ax.set_xlabel('Bin Center')\n",
    "ax.set_ylabel('Row Index')\n",
    "ax.set_zlabel('Frequency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_nodes.mean(0).mean(1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stds = train_pool_nodes.mean(-1).std(-1).mean(0)\n",
    "mean_values = train_pool_nodes.mean(-1).mean(0).mean(-1)\n",
    "stds_train = train_nodes.mean(-1).std(-1).mean(0)\n",
    "mean_values_train = train_nodes.mean(-1).mean(0).mean(-1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.fill_between(range(mean_values.shape[0]), mean_values - stds, mean_values + stds, alpha=0.2)\n",
    "plt.fill_between(range(mean_values_train.shape[0]), mean_values_train - stds_train, mean_values_train + stds_train, alpha=0.2)\n",
    "plt.plot(mean_values, label=\"Selection pool\")\n",
    "plt.plot(mean_values_train, label=\"Train set\")\n",
    "plt.xlim(left=0, right=27)\n",
    "plt.title(\"Average node filtering ratio by iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Node filtering ratio\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "stds.shape, mean_values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = node_filtering.mean(-1).std(-1).mean(0)\n",
    "mean_values = node_filtering.mean(-1).mean(0).mean(-1)\n",
    "plt.fill_between(range(mean_values.shape[0]), mean_values - stds, mean_values + stds, alpha=0.2)\n",
    "plt.plot(mean_values)\n",
    "plt.xlim(left=0, right=27)\n",
    "plt.title(\"Average ratio of filtered nodes by iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Ratio of filtered nodes\")\n",
    "plt.show()\n",
    "stds.shape, mean_values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSITIVITY TO SPLIT AND MODEL INITIALIZATION\n",
    "# GRAPH ADAPTATION BEHAVES WEIRD\n",
    "# Get the accuracy array\n",
    "accuracies = {k:v[2] for k,v in metrics_dict_cora_gcn.items()}\n",
    "accuracy_array = accuracies[\"aleatoric_propagated_fmask_emask_2000_filter_probs_0.5_0.4\"]\n",
    "\n",
    "# Split the array into bins of 5 items each\n",
    "bins = np.array(np.array_split(accuracy_array, len(accuracy_array) // 5))\n",
    "\n",
    "# Calculate the standard deviation for each bin\n",
    "std_inside_split = np.std(bins, axis=1)\n",
    "std_inside_init = np.std(bins, axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# First subplot\n",
    "axs[0].plot(np.std(std_inside_split, axis=0), label=\"STD by init\")\n",
    "axs[0].plot(np.std(std_inside_init, axis=0), label=\"STD by split\")\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Standard Deviation by Init and Split\")\n",
    "\n",
    "# Second subplot\n",
    "axs[1].plot(np.mean(std_inside_split, axis=0), label=\"STD by init\")\n",
    "axs[1].plot(np.mean(std_inside_init, axis=0), label=\"STD by split\")\n",
    "axs[1].plot(np.std(accuracy_array, axis=0), label=\"std\")\n",
    "axs[1].legend()\n",
    "axs[1].set_title(\"Mean by Init and Split\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot std_inside_split\n",
    "axs[0].plot(std_inside_split.T)\n",
    "axs[0].set_title(\"Standard Deviation Inside Split\")\n",
    "axs[0].set_xlabel(\"Index\")\n",
    "axs[0].set_ylabel(\"Standard Deviation\")\n",
    "\n",
    "# Plot std_inside_init\n",
    "axs[1].plot(std_inside_init.T)\n",
    "axs[1].set_title(\"Standard Deviation Inside Initialization\")\n",
    "axs[1].set_xlabel(\"Index\")\n",
    "axs[1].set_ylabel(\"Standard Deviation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.sort_values(by=\"28_mean\", ascending=False)\n",
    "df_ranked = df_combined[[\"5_mean\",\"10_mean\", \"20_mean\", \"28_mean\"]].rank(ascending=False)\n",
    "df_ranked[\"sum\"] = df_ranked.sum(axis=1)\n",
    "df_ranked.sort_values(by=\"sum\", ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"sum\"] = df_combined[[\"5_mean\",\"10_mean\", \"20_mean\", \"28_mean\"]].sum(axis=1)\n",
    "df_combined.sort_values(by=\"sum\", ascending=False)[[\"5_mean\",\"10_mean\", \"20_mean\", \"28_mean\",\"sum\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_dict(t):\n",
    "    ixs = torch.tensor([l[1:] for l in t[\"acquired_idxs\"][:10]]).flatten()\n",
    "    count = torch.bincount(ixs)\n",
    "    keys = torch.where(count)\n",
    "    count_dict = {k.item():count[k].item() for k in keys[0]}\n",
    "    return count_dict, count,ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict_cora_gcn.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORA SGC TTA\n",
    "df_cora_sgc_tta = df_combined[df_combined.index.str.contains(\"aleatoric_propagated\") & df_combined.index.str.contains(\"probs\") & ~df_combined.index.str.contains(\"educated\")].copy()\n",
    "\n",
    "df_cora_sgc_tta = process_tta(df_cora_sgc_tta)\n",
    "\n",
    "df_cora_sgc_tta = df_cora_sgc_tta[df_cora_sgc_tta[\"num\"] == 100] \n",
    "df_cora_sgc_tta_mask = df_cora_sgc_tta[df_cora_sgc_tta[\"m_f\"] == \"mask\"]\n",
    "df_cora_sgc_tta_noise = df_cora_sgc_tta[df_cora_sgc_tta[\"m_f\"] == \"noise\"]\n",
    "pivot_table_sgc_mask = df_cora_sgc_tta_mask.pivot(index=\"p_f\", columns=\"p_e\", values=\"28_mean\")\n",
    "pivot_table_sgc_mask.sort_index(inplace=True, ascending=False)\n",
    "pivot_table_sgc_noise = df_cora_sgc_tta_noise.pivot(index=\"p_f\", columns=\"p_e\", values=\"28_mean\")\n",
    "pivot_table_sgc_noise.sort_index(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [get_count_dict(metrics_dict_cora_gcn[x][3]) for x in tta_df.index]\n",
    "tta_df[\"num_acquired_indices\"] = [len(i[0]) for i in l]\n",
    "tta_df[\"num_acquired_indices\"] /= 700\n",
    "tta_df[\"max_acquired\"] = [i[1].max().item() for i in l]\n",
    "tta_df[\"max_acquired_index\"] = [i[1].argmax().item() for i in l]\n",
    "\n",
    "tta_df_combined_mask = tta_df[~tta_df[\"p_e\"].isna() & ~tta_df[\"p_f\"].isna() & (tta_df[\"m_f\"] == \"noise\")& (tta_df[\"filter\"] == \"nofilter\")]\n",
    "pt = tta_df_combined_mask.pivot(index=\"p_f\", columns=\"p_e\", values=\"num_acquired_indices\").sort_index(ascending=False)\n",
    "sns.heatmap(pt, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"aleatoric_propagated_fmask_emask_200_filter_probs_0.5_0.4\"\n",
    "key2 = \"geem\"\n",
    "\n",
    "\n",
    "count_dict_1, count_1, ixs_1 = get_count_dict(metrics_dict_cora_gcn[key1][3])\n",
    "# count_dict_1, count_1, ixs_1 = get_count_dict(runs)\n",
    "print(f\"Maximally acquired index: {count_1.argmax()} with {count_1.max()} acquisitions\")\n",
    "\n",
    "count_dict_2, count_2, ixs_2 = get_count_dict(metrics_dict_cora_gcn[key2][3])\n",
    "print(f\"Maximally acquired index: {count_2.argmax()} with {count_2.max()} acquisitions\")\n",
    "print(\"------\")\n",
    "\n",
    "print(f\"Intersection of acquired indices: {len(set(count_dict_1.keys()).intersection(set(count_dict_2.keys())))}\")\n",
    "print(f\"Union of acquired indices: {len(set(count_dict_1.keys()).union(set(count_dict_2.keys())))}\")\n",
    "print(f\"{key1} acquired indices: {len(count_dict_1)}\")\n",
    "print(f\"{key2} acquired indices: {len(count_dict_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in metrics_dict_cora_gcn.keys() if k.startswith(\"aleatoric_propagated_fnoise_emask_100_filter_probs\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[metrics_dict_cora_gcn[x] for x in big_cora_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for k,v in metrics_dict_cora_gcn.items():\n",
    "    cd, c, i = get_count_dict(v[3])\n",
    "    d.append([k,len(cd), c.max().item(), c.argmax().item()])\n",
    "\n",
    "count_dict_df = pd.DataFrame(d, columns=[\"key\", \"num_acquired_indices\", \"max_acquisitions\", \"max_acquisition_index\"])\n",
    "count_dict_df.sort_values(by=\"num_acquired_indices\", ascending=True, inplace=True)\n",
    "count_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict, count, ixs =  get_count_dict(metrics_dict_cora_gcn[key1][3])\n",
    "\n",
    "plt.hist(list(count_dict.values()), bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
